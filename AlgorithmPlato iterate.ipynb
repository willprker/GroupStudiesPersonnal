{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrumProcessorPlato import PowerSpectrumProcessor\n",
    "from IterativeSNR import IterativeSNRAnalyzer\n",
    "from noiseAddition import NoiseAddition\n",
    "from bestFilters import BestFilters\n",
    "from gaussianFitter import GaussianWrapper\n",
    "from Spacings_Class import Spacings\n",
    "from Exoplanets import ExoplanetAnalysis\n",
    "from MassRadExtract import M_R_Est\n",
    "from MassComparison import MassComparison\n",
    "from RadiusComparison import StellarParameterComparison\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to the clean spectrums. Send to a new folder for F/S's algorithm to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_dir = \"algoSpectrum\"\n",
    "\n",
    "for filename in os.listdir(spectrum_dir):\n",
    "    if filename.endswith(\".pow\"):\n",
    "        filepath = os.path.join(spectrum_dir, filename)\n",
    "        noise_sim = NoiseAddition(filepath, vmag_option=\"random\", manual_vmag=None, num_vmags=6)\n",
    "        noise_sim.add_noise() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F/S's run all of the stars with the noise added. Output Yes/Maybe/No. Save all of the results to a csv. The Maybe's and No's are sent to a separate folder for W/L/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = \"NosiyData\"\n",
    "\n",
    "analyzer = IterativeSNRAnalyzer(input_directory=r\"NoisyData\")\n",
    "analyzer.process_files(percentlimit=14, noiselimit=10, greyarea=2, use_maybe_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def custom_sort(file_name):\n",
    "    \"\"\"Extracts spectrum number and vmag from the filename.\"\"\"\n",
    "    match = re.match(r\"spectrum_(\\d+)_cams24_vmag(\\d+\\.\\d+)\\.pow\", file_name)\n",
    "    if match:\n",
    "        return int(match.group(1)), float(match.group(2))\n",
    "    return (float('inf'), float('inf'))  # Put unmatched filenames at the end\n",
    "\n",
    "def sort_csv(file_path):\n",
    "    \"\"\"Reads a CSV, sorts it, and replaces the original CSV.\"\"\"\n",
    "    df = pd.read_csv(file_path, header=None)  # No header\n",
    "\n",
    "    df['sort_keys'] = df[0].apply(custom_sort)\n",
    "    df = df.sort_values(by='sort_keys').drop(columns=['sort_keys'])\n",
    "\n",
    "    # Save to CSV, overwriting the original file, no header\n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "# Example usage (replace 'your_file.csv' with your actual file path)\n",
    "sort_csv(\"iterative analysis output//Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collcet the files from F/S's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = \"NoisyData\"\n",
    "\n",
    "for filename in os.listdir(noise_dir):\n",
    "    if filename.endswith(\".pow\"):\n",
    "        filepath = os.path.join(noise_dir, filename)\n",
    "        filter = PowerSpectrumProcessor(filepath)\n",
    "        filter.load_power_spectrum()\n",
    "        filter.run_filtering()\n",
    "        filter.run_baseline_subtraction()\n",
    "        filter.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W's algorithm runs the Maybe's and No's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dir = \"filterOutput\"\n",
    "\n",
    "for filename in os.listdir(filter_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(filter_dir, filename)\n",
    "        best_filters = BestFilters(filepath)\n",
    "        best_filters.process_and_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save CSV, with best 3, for L/F to run their section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "best_dir = \"bestFilters\"\n",
    "output_csv = \"Results.csv\"\n",
    "temp_csv = \"Results_temp.csv\"\n",
    "\n",
    "# Read existing results into a list (since multiple rows may exist per filename)\n",
    "results_list = []\n",
    "\n",
    "try:\n",
    "    with open(output_csv, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        fieldnames = reader.fieldnames\n",
    "        for row in reader:\n",
    "            results_list.append(row)  # Store each row in a list\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {output_csv} not found. Ensure the file exists.\")\n",
    "    fieldnames = [\"filename\", \"gaussian\", \"spacings\", \"nu_max\", \"error nu_max\", \"delta nu\", \"error delta nu\"]\n",
    "\n",
    "# Process new data and update matching rows\n",
    "for filename in os.listdir(best_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(best_dir, filename)\n",
    "        print(f\"Processing file: {filepath}\")\n",
    "        \n",
    "        try:\n",
    "            gw = GaussianWrapper(filepath)\n",
    "            gauss_status, nu_max, envelope_indices, best_fit_no = gw.run_wrapper()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing GaussianWrapper for {filename}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if len(nu_max) < 2:\n",
    "            print(f\"Warning: nu_max has insufficient elements in file {filename}: {nu_max}\")\n",
    "            nu_max = [None, None]  # Default values to avoid index errors\n",
    "        \n",
    "        try:\n",
    "            s = Spacings(filepath, envelope_indices, best_fit_no)\n",
    "            spacing_status, delta_nu, error = s.spacings()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing Spacings for {filename}: {e}\")\n",
    "            spacing_status, delta_nu, error = None, None, None\n",
    "\n",
    "        base_filename = os.path.splitext(filename)[0]  # Strip .csv\n",
    "        \n",
    "        # Find matching row(s) in Results.csv\n",
    "        updated = False\n",
    "        for row in results_list:\n",
    "            row_base = os.path.splitext(row[\"filename\"])[0]  # Strip .pow from Results.csv entry\n",
    "\n",
    "            if row_base == base_filename:\n",
    "                print(f\"Updating entry for {filename}\")\n",
    "                # Update only missing values\n",
    "                row[\"gaussian\"] = row[\"gaussian\"] or gauss_status\n",
    "                row[\"spacings\"] = row[\"spacings\"] or spacing_status\n",
    "                row[\"nu_max\"] = row[\"nu_max\"] or nu_max[0]\n",
    "                row[\"error nu_max\"] = row[\"error nu_max\"] or nu_max[1]\n",
    "                row[\"delta nu\"] = row[\"delta nu\"] or delta_nu\n",
    "                row[\"error delta nu\"] = row[\"error delta nu\"] or error\n",
    "                updated = True\n",
    "\n",
    "        if not updated:\n",
    "            print(f\"Warning: No matching entry found for {filename} in {output_csv}\")\n",
    "\n",
    "# Write updated results back to the CSV file\n",
    "try:\n",
    "    with open(temp_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results_list)\n",
    "    os.replace(temp_csv, output_csv)\n",
    "    print(f\"Updated results saved to {output_csv}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = 'Results.csv'\n",
    "spectra_folder_path = 'NoisyData'\n",
    "\n",
    "processor = M_R_Est(csvpath, spectra_folder_path, ExoplanetAnalysis)\n",
    "processor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_pow_data(filepath):\n",
    "    \"\"\"\n",
    "    Extracts nu max, delta nu, actual mass, and actual radius from a .pow file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the .pow file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted data, or None if not found.\n",
    "              Keys: 'nu_max', 'delta_nu', 'actual_mass', 'actual_radius'.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='latin-1') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('#'):\n",
    "                    parts = line[1:].strip().split(':')\n",
    "                    if len(parts) == 2:\n",
    "                        key = parts[0].strip()\n",
    "                        value_str = parts[1].strip().split()[0]  # Take only the first word as value\n",
    "                        try:\n",
    "                            if key == 'nu_max':\n",
    "                                data['nu_max'] = float(value_str)\n",
    "                            elif key == 'delta_nu':\n",
    "                                data['delta_nu'] = float(value_str)\n",
    "                            elif key == 'Mact':\n",
    "                                data['actual_mass'] = float(value_str)\n",
    "                            elif key == 'Radius':\n",
    "                                data['actual_radius'] = float(value_str)\n",
    "                        except ValueError:\n",
    "                            print(f\"Warning: Could not convert value to float for key '{key}' in line: {line} in {filepath}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {filepath}\")\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "def add_pow_data_to_csv(csv_filepath, pow_files_directory):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, extracts data from corresponding .pow files,\n",
    "    and adds the data as new columns to the CSV.\n",
    "\n",
    "    Args:\n",
    "        csv_filepath (str): The path to the CSV file.\n",
    "        pow_files_directory (str): The directory containing the .pow files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found: {csv_filepath}\")\n",
    "        return\n",
    "\n",
    "    nu_max_list = []\n",
    "    delta_nu_list = []\n",
    "    actual_mass_list = []\n",
    "    actual_radius_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        pow_filename = row['filename']  # Get the filename directly from the 'filename' column\n",
    "        pow_filepath = os.path.join(pow_files_directory, pow_filename)\n",
    "\n",
    "        extracted_data = extract_pow_data(pow_filepath)\n",
    "\n",
    "        if extracted_data:\n",
    "            nu_max_list.append(extracted_data.get('nu_max'))\n",
    "            delta_nu_list.append(extracted_data.get('delta_nu'))\n",
    "            actual_mass_list.append(extracted_data.get('actual_mass'))\n",
    "            actual_radius_list.append(extracted_data.get('actual_radius'))\n",
    "        else:\n",
    "            nu_max_list.append(None)\n",
    "            delta_nu_list.append(None)\n",
    "            actual_mass_list.append(None)\n",
    "            actual_radius_list.append(None)\n",
    "\n",
    "    df['actual_nu_max'] = nu_max_list  # Changed column name to avoid potential confusion with 'nu_max' guess\n",
    "    df['actual_delta_nu'] = delta_nu_list # Changed column name\n",
    "    df['actual_mass'] = actual_mass_list\n",
    "    df['actual_radius'] = actual_radius_list\n",
    "\n",
    "    df.to_csv(csv_filepath, index=False)\n",
    "    print(f\"Successfully added data from .pow files to {csv_filepath}\")\n",
    "\n",
    "# Example usage (assuming you have a 'Results.csv' with a 'filename' column\n",
    "# and a directory named 'NoisyData' containing your .pow files)\n",
    "csv_file = 'Results.csv'\n",
    "pow_dir = 'NoisyData'\n",
    "\n",
    "add_pow_data_to_csv(csv_file, pow_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"Results.csv\"  # Update with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the columns to compare and their corresponding error columns\n",
    "comparison_columns = {\n",
    "    \"nu_max\": (\"actual_nu_max\", \"error nu_max\"),\n",
    "    \"delta nu\": (\"actual_delta_nu\", \"error delta nu\"),\n",
    "    \"mass guess\": (\"actual_mass\", \"mass error\"),\n",
    "    \"radius guess\": (\"actual_radius\", \"radius error\")\n",
    "}\n",
    "\n",
    "# Ensure 'gaussian' and 'spacing' columns exist and filter only rows where both are True\n",
    "if \"gaussian\" in df.columns and \"spacings\" in df.columns:\n",
    "    df_filtered = df[(df[\"gaussian\"] == True) & (df[\"spacings\"] == True)].copy()  # Filter the dataframe and create a copy to avoid SettingWithCopyWarning\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Generate scatter plots with y=x reference line and error bars\n",
    "    for i, (obtained, (actual, error)) in enumerate(comparison_columns.items()):\n",
    "        ax = axes[i]\n",
    "        x = df_filtered[actual]\n",
    "        y = df_filtered[obtained]\n",
    "        y_err = df_filtered[error]  # Get the error values\n",
    "\n",
    "        # Scatter plot with error bars\n",
    "        ax.errorbar(x, y, fmt='x', color='blue', label='Values', alpha=0.7, capsize=3)  # added yerr\n",
    "\n",
    "        # y = x reference line\n",
    "        min_val = min(x.min(), y.min())\n",
    "        max_val = max(x.max(), y.max())\n",
    "        buffer = (max_val - min_val) * 0.05  # 5% buffer to avoid points at the edges\n",
    "        line_range = np.linspace(min_val - buffer, max_val + buffer, 100)\n",
    "        ax.plot(line_range, line_range, color='red', linestyle='dashed', label='Optimal fit')\n",
    "\n",
    "        # Set x and y limits\n",
    "        ax.set_xlim(min_val - buffer, max_val + buffer)\n",
    "        ax.set_ylim(min_val - buffer, max_val + buffer)\n",
    "\n",
    "        # Labels and title\n",
    "        ax.set_xlabel(f\"Actual {obtained}\")\n",
    "        ax.set_ylabel(f\"Obtained {obtained}\")\n",
    "        ax.set_title(f\"{obtained} vs. Actual {obtained}\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Columns 'gaussian' or 'spacing' not found. Exiting.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
